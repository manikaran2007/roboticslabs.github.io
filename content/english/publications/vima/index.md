---
title: "VIMA: General Robot Manipulation with Multimodal Prompts"
meta_title: "VIMA"
description: "Multimodal LLM for robot manipulation; unifies diverse robotics tasks in a single prompting framework."
date: 2022-10-07
categories: []
authors: ["Yunfan Jiang", "Agrim Gupta", "Zichen 'Charles' Zhang", "Guanzhi Wang", "Yongqiang Dou", "Yanjun Chen", "Li Fei-Fei", "Anima Anandkumar", "Yuke Zhu", "Linxi 'Jim' Fan"]
tags: []
draft: false
link: https://vimalabs.github.io/
sources:
    - name: arxiv
      link: https://arxiv.org/abs/2210.03094
      icon: "ai ai-arxiv"

    - name: pdf
      link: https://vimalabs.github.io/assets/vima_paper.pdf
      icon: "fa-regular fa-file-pdf"

    - name: code
      link: https://github.com/vimalabs/VIMA
      icon: "fa-brands fa-github"

    - name: models
      link: https://github.com/vimalabs/VIMA#pretrained-models
      icon: "fa fa-network-wired"

    - name: benchmark
      link: https://github.com/vimalabs/VimaBench
      icon: "fas fa-robot"

    - name: dataset
      link: https://huggingface.co/datasets/VIMA/VIMA-Data
      icon: "fas fa-database"

---

aa